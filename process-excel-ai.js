// AI-Powered Excel Processing with Ollama (qwen3-coder:480b-cloud)
import axios from "axios";
import dotenv from "dotenv";
import { availableFunctions, functionDefinitions } from "./tools.js";
import { STANDARD_COLUMNS } from "./constants.js";

dotenv.config();

const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || "http://localhost:11434";
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || "qwen3-coder:480b-cloud";
const UPLOAD_DIR = process.env.UPLOAD_DIR || "./upload";
const OUTPUT_DIR = process.env.OUTPUT_DIR || "./output";
const MAX_SAMPLE_SIZE = parseInt(process.env.MAX_SAMPLE_SIZE || "5", 10);
const LARGE_FILE_THRESHOLD = parseInt(process.env.LARGE_FILE_THRESHOLD || "100", 10);

// Execute function calls from Ollama
async function executeFunctionCall(functionCall) {
  const functionName = functionCall.name;
  let functionArgs;

  if (typeof functionCall.arguments === "string") {
    functionArgs = JSON.parse(functionCall.arguments);
  } else if (typeof functionCall.arguments === "object") {
    functionArgs = functionCall.arguments;
  } else {
    throw new Error(
      `Invalid arguments format: ${typeof functionCall.arguments}`
    );
  }

  if (availableFunctions[functionName]) {
    console.log(`   üîß ${functionName}`);
    const result = await availableFunctions[functionName](functionArgs);

    // Show concise result
    if (result.success === false) {
      console.log(
        `      ‚ùå Error: ${result.error?.message || "Unknown error"}`
      );
    } else if (functionName === "readExcelFileSample") {
      console.log(
        `      ‚úÖ Sampled ${result.sampleRows?.length || 0} rows (from ${
          result.totalRows
        } total) with ${result.headers?.length || 0} columns`
      );
    } else if (functionName === "analyzeColumnRelationships") {
      const rel = result.relationships || {};
      console.log(`      ‚úÖ ${result.message}`);
      if (rel.hasNameSplit) {
        console.log(
          `         üìù Name split detected: ${Object.values(
            rel.nameComponents
          ).join(" + ")}`
        );
      }
      if (rel.hasAddressSplit) {
        console.log(
          `         üìç Address split detected: ${
            Object.keys(rel.addressComponents).length
          } components`
        );
      }
      if (rel.hasCombinedAddress) {
        console.log(
          `         üìç Combined address found in: ${rel.combinedAddressColumn}`
        );
      }
    } else if (functionName === "combineNameFields") {
      console.log(`      ‚úÖ ${result.message}`);
    } else if (functionName === "consolidateAddress") {
      console.log(`      ‚úÖ ${result.message}`);
    } else if (functionName === "createColumnMapping") {
      console.log(`      ‚úÖ Mapped ${result.mappedColumns}/10 columns`);
    } else if (functionName === "transformRows") {
      console.log(`      ‚úÖ Transformed ${result.rowCount} rows to 10 columns`);
    } else if (functionName === "transformAndWriteFile") {
      console.log(
        `      ‚úÖ Processed ${result.rowsProcessed} rows ‚Üí ${result.outputFile}`
      );
      console.log(`      üìÅ Output: ${result.filePath}`);
    } else if (functionName === "readExcelFileFull") {
      console.log(
        `      ‚úÖ Read ${result.rows?.length || 0} of ${
          result.totalRows
        } total rows`
      );
    } else if (functionName === "validateExcelMapping") {
      const passed = result.validationPassed ? "‚úÖ PASSED" : "‚ö†Ô∏è  HAS ISSUES";
      console.log(
        `      ${passed} - ${result.issues?.length || 0} errors, ${
          result.warnings?.length || 0
        } warnings`
      );
      if (result.issues && result.issues.length > 0) {
        result.issues.forEach((issue) => {
          console.log(`         ‚ùå ${issue.column}: ${issue.issue}`);
        });
      }
      if (
        result.warnings &&
        result.warnings.length > 0 &&
        result.warnings.length <= 5
      ) {
        result.warnings.forEach((warning) => {
          console.log(`         ‚ö†Ô∏è  ${warning.column}: ${warning.issue}`);
        });
      } else if (result.warnings && result.warnings.length > 5) {
        console.log(
          `         ‚ö†Ô∏è  ${result.warnings.length} warnings (showing first 3):`
        );
        result.warnings.slice(0, 3).forEach((warning) => {
          console.log(`         ‚ö†Ô∏è  ${warning.column}: ${warning.issue}`);
        });
      }
    } else if (functionName === "writeExcelFile") {
      console.log(
        `      ‚úÖ Wrote ${result.rowsWritten} rows to ${result.filePath}`
      );
    } else {
      console.log(`      ‚úÖ ${result.message || "Success"}`);
    }

    return result;
  } else {
    throw new Error(`Function ${functionName} not found`);
  }
}

async function processExcelWithAI(fileName) {
  try {
    // Determine file type
    const isCSV = fileName.toLowerCase().endsWith('.csv');
    const isXLSX = fileName.toLowerCase().endsWith('.xlsx');
    const fileType = isCSV ? 'CSV' : 'Excel';

    if (!isCSV && !isXLSX) {
      console.error(`‚ùå Unsupported file format: ${fileName}`);
      console.error('   Supported formats: .xlsx, .csv');
      return;
    }

    console.log(`üöÄ Starting AI-Powered ${fileType} Processing...\n`);
    console.log(`ü§ñ Using model: ${OLLAMA_MODEL}`);
    console.log(`üìÅ File: ${fileName}\n`);

    // Step 1: Verify file exists
    console.log("üìÇ Verifying file exists...");

    // List all supported files
    const xlsxList = await availableFunctions.listFiles({
      directory: UPLOAD_DIR,
      extension: ".xlsx",
    });
    const csvList = await availableFunctions.listFiles({
      directory: UPLOAD_DIR,
      extension: ".csv",
    });
    const allFiles = [...xlsxList.files, ...csvList.files];

    if (!allFiles.includes(fileName)) {
      console.error(`‚ùå File not found: ${fileName}`);
      console.log(`   Available files: ${allFiles.join(", ")}`);
      return;
    }
    console.log(`‚úÖ File found: ${fileName}\n`);

    // Step 2: Send to Ollama API with function calling
    console.log("ü§ñ Sending request to Ollama AI...\n");

    const SYSTEM_PROMPT = `# PURPOSE
You are designed to standardize messy customer data files (Excel/CSV) into a clean, uniform 10-column format. Your purpose is to help organizations transform inconsistent data structures from various sources into a single standardized database-ready format.

# CAPABILITIES
You can intelligently:
- Analyze varying column structures and identify data patterns
- Map columns semantically (understanding "phone" means "Contact Number", "purchase_date" means "Date", etc.)
- Combine split data (First Name + Last Name ‚Üí Name, City + Country ‚Üí Address)
- Detect and convert Excel serial dates to readable formats
- Handle both Excel (.xlsx) and CSV (.csv) files
- Process files of any size (small files with validation, large files with batch processing)
- Distinguish between relevant and irrelevant data (e.g., Company ‚â† Product, Index ‚â† Amount)
- Leave columns empty when no relevant data exists (never force-map unrelated data)

# YOUR TASK
Transform the uploaded file "${fileName}" into the standardized 10-column format using intelligent column mapping and data consolidation.

# OUTPUT FORMAT (Required Columns in Exact Order)
1. Date - Transaction/purchase date
2. Name - Full customer name
3. Age - Customer age
4. Address - Complete address
5. Gender - M/F/Male/Female
6. Contact Number - Phone number
7. Product Purchased - Product/item/service name
8. Amount - Price/cost/payment amount
9. Product Quantity - Quantity purchased
10. Email - Email address

# CRITICAL PRINCIPLE
‚ö†Ô∏è ONLY map columns when you find RELEVANT and APPROPRIATE data in the source file.
‚ö†Ô∏è If NO relevant data exists for a column, leave it as EMPTY STRING ("").
‚ö†Ô∏è NEVER force-map unrelated data just to fill columns.

# EXECUTION WORKFLOW

STEP 1: Analyze Structure
- Call readExcelFileSample(directory="${UPLOAD_DIR}", fileName="${fileName}", sampleSize=${MAX_SAMPLE_SIZE})
- Note the totalRows count from the result
- Call analyzeColumnRelationships(headers from step 1, sampleRows from step 1)

‚ö†Ô∏è CRITICAL: Carefully examine the analyzeColumnRelationships result:

Name Status Check:
  ‚úÖ hasNameSplit=true AND nameComponents has "First Name" AND "Last Name"
     ‚Üí Names are in SEPARATE columns (e.g., "Robert" in one, "Garcia" in another)
     ‚Üí Action: You WILL use nameColumns parameter in Step 3

  ‚ùå hasNameSplit=false OR only single name column exists
     ‚Üí Name is ALREADY COMBINED in one column (e.g., "Robert Garcia" together)
     ‚Üí Action: DO NOT use nameColumns parameter - map directly in Step 2

Address Status Check:
  ‚úÖ hasAddressSplit=true AND addressComponents has multiple fields
     ‚Üí Address is split (e.g., "City" in one column, "Country" in another)
     ‚Üí Action: You WILL use addressComponents parameter in Step 3

  ‚ùå hasAddressSplit=false OR single address column exists
     ‚Üí Address is already combined or doesn't exist
     ‚Üí Action: DO NOT use addressComponents parameter - map directly in Step 2

Address Component Rules:
- ONLY include: Street, Apartment, City, State, Postal Code, Country
- NEVER include: Customer ID, User ID, Index, Row Number, Company, Organization

STEP 2: Create Intelligent Mapping
Action: Call createColumnMapping with a mapping object for all 10 columns

Mapping Strategy:
1. Check exact column name matches (case-insensitive)
2. Check semantic similarities (e.g., "purchase_date" ‚Üí Date)
3. Analyze sample data content (e.g., values with "@" ‚Üí Email)
4. Apply column-specific rules below

Column-Specific Mapping Rules:

üìÖ Date:
   ‚úÖ Map: Date, Transaction Date, Purchase Date, Subscription Date, Order Date
   ‚ùå Do NOT map: Unrelated date fields

üë§ Name:
   IF hasNameSplit=false (single name column):
      ‚úÖ Map directly: "Name" ‚Üí Name, "Full Name" ‚Üí Name, "Customer Name" ‚Üí Name
      ‚ö†Ô∏è This column already has complete names like "Robert Garcia"
      ‚ö†Ô∏è DO NOT combine anything - just map the column name

   IF hasNameSplit=true (split across First Name + Last Name):
      ‚ùå Leave as "" in mapping (will be combined using nameColumns parameter in Step 3)
      ‚ö†Ô∏è DO NOT map any single column to Name - combination happens automatically

üéÇ Age:
   ‚úÖ Map: Age, Customer Age
   ‚ùå Do NOT map: Index, ID, Row Number

üìç Address:
   ‚úÖ Map: Address, Full Address, Complete Address
   ‚ö†Ô∏è If split (City + Country, etc.): Leave as "" (handled separately)

‚öß Gender:
   ‚úÖ Map: Gender, Sex, M/F, Male/Female
   ‚ùå Do NOT map: Single-letter columns without M/F values

üìû Contact Number:
   ‚úÖ Map: Phone, Mobile, Telephone, Cell, Contact Number
   ‚ùå NEVER map: CNIC, NID, SSN, ID Number, Customer ID, Account ID

üõçÔ∏è Product Purchased:
   ‚úÖ Map: Product, Product Name, Item, Item Name, Service, SKU
   ‚ùå NEVER map: Company, Company Name, Business, Organization, Employer, Vendor

üí∞ Amount:
   ‚úÖ Map: Amount, Price, Cost, Total, Payment
   ‚ùå NEVER map: Index, Row Number, Customer ID, Serial Number

üì¶ Product Quantity:
   ‚úÖ Map: Quantity, Qty, Count, Units, Items
   ‚ùå NEVER map: Index, Row Number, Customer ID, Serial Number

üìß Email:
   ‚úÖ Map: Email, E-mail, Email Address
   ‚ùå Do NOT map: Columns without @ symbol in sample data

Default Rule:
‚ö†Ô∏è If NO relevant source column exists ‚Üí Use empty string ""
‚ö†Ô∏è Never force-map unrelated columns just to fill output

Special Handling:
- For split names: Leave "Name" as "" in mapping (will use nameColumns parameter)
- For split addresses: Leave "Address" as "" in mapping (will use addressComponents parameter)

STEP 3: Transform and Write File

Check totalRows from Step 1, then choose the appropriate method:

üìä LARGE FILES (> ${LARGE_FILE_THRESHOLD} rows) - Batch Processing:
   Function: transformAndWriteFile()

   Required Parameters:
   - sourceDirectory: "${UPLOAD_DIR}"
   - sourceFileName: "${fileName}"
   - outputDirectory: "${OUTPUT_DIR}"
   - outputFileName: "processed_${fileName}"
   - mapping: (the mapping object from Step 2)
   - mappingId: (the ID from Step 2)

   ‚ö†Ô∏è CRITICAL - Optional Parameters (based on Step 1 analysis):

   nameColumns parameter:
     ‚úÖ ONLY pass if: hasNameSplit=true AND you have separate "First Name" & "Last Name" columns
        Example: { firstName: "First Name", lastName: "Last Name", middleName: "Middle Name" }

     ‚ùå DO NOT pass if: hasNameSplit=false OR you have a single "Name" column
        Reason: Single name column is already mapped in Step 2 - passing this causes DUPLICATION

   addressComponents parameter:
     ‚úÖ ONLY pass if: hasAddressSplit=true AND you have multiple separate address columns
        Valid fields: street, apartment, city, state, postal, country
        Example: { city: "City", country: "Country", state: "State" }

     ‚ùå DO NOT pass if: hasAddressSplit=false OR you have single "Address" column
        ‚ùå NEVER include: Customer ID, Index, Company, Row Number in addressComponents

   Behavior:
   - Processes file server-side in batches (you never see full data)
   - Combines names and addresses automatically
   - No validation (to avoid context limits)
   - After completion: STOP immediately

üìÑ SMALL FILES (‚â§ ${LARGE_FILE_THRESHOLD} rows) - Full Processing:
   1. Call readExcelFileFull(directory="${UPLOAD_DIR}", fileName="${fileName}")

   2. Name Handling:
      IF hasNameSplit=true (First Name + Last Name in separate columns):
         ‚Üí Call combineNameFields ‚Üí manually construct rows with combined names
      ELSE (single "Name" column or no name column):
         ‚Üí DO NOT call combineNameFields - names already in mapping

   3. Address Handling:
      IF hasAddressSplit=true (City + Country in separate columns):
         ‚Üí Call consolidateAddress ‚Üí manually construct rows with consolidated addresses
      ELSE (single "Address" column or no address column):
         ‚Üí DO NOT call consolidateAddress - address already in mapping

   4. IF you did NOT call combineNameFields or consolidateAddress:
         ‚Üí Call transformRows(mappingId, sourceRows, sourceHeaders)

   5. Validate: Call validateExcelMapping(first ${MAX_SAMPLE_SIZE}-10 rows)
   6. Write: Call writeExcelFile(directory="${OUTPUT_DIR}", fileName="processed_${fileName}", data=rows)

# CONSTRAINTS
1. ‚ö†Ô∏è Empty Column Rule: If no relevant data exists for ANY column, use empty string ""
2. ‚ö†Ô∏è Never map unrelated data (Index ‚Üí Amount, Company ‚Üí Product, etc.)
3. ‚ö†Ô∏è NO DUPLICATION: If name is already in one column, DO NOT use nameColumns parameter
4. ‚ö†Ô∏è After file is written: STOP immediately - do NOT call any more functions
5. ‚ö†Ô∏è Execute autonomously - do NOT ask for user permission
6. ‚ö†Ô∏è Respect column data types (analyze sample values, not just names)

# START
Begin execution by calling readExcelFileSample now.`;

    const messages = [
      {
        role: "system",
        content: SYSTEM_PROMPT,
      },
      {
        role: "user",
        content: `Process the file "${fileName}". Start by calling readExcelFileSample to analyze the file structure.`,
      },
    ];

    let stepCount = 0;
    let isComplete = false;
    const maxSteps = 20; // Safety limit

    while (!isComplete && stepCount < maxSteps) {
      console.log(`\nüì§ AI Request: Step ${stepCount + 1}`);

      const response = await axios.post(
        `${OLLAMA_BASE_URL}/api/chat`,
        {
          model: OLLAMA_MODEL,
          messages: messages,
          tools: functionDefinitions.map((func) => ({
            type: "function",
            function: {
              name: func.name,
              description: func.description,
              parameters: func.parameters,
            },
          })),
          stream: false,
        },
        {
          headers: { "Content-Type": "application/json" },
          timeout: 300000, // 5 minute timeout
        }
      );

      const message = response.data.message;
      const toolCalls = message.tool_calls || [];

      if (toolCalls.length > 0) {
        // Execute function calls
        for (const toolCall of toolCalls) {
          const functionName = toolCall.function.name;
          const result = await executeFunctionCall(toolCall.function);

          // Add AI message
          messages.push({
            role: "assistant",
            content: message.content || "",
            tool_calls: toolCalls,
          });

          // Add function result
          messages.push({
            role: "tool",
            content: JSON.stringify(result),
            tool_call_id: toolCall.id,
          });

          stepCount++;

          // Check if this is the final step (writeExcelFile or transformAndWriteFile)
          if (functionName === "writeExcelFile" || functionName === "transformAndWriteFile") {
            console.log(
              "\n‚úÖ Processing completed - File written successfully"
            );
            isComplete = true;
            break;
          }
        }
      } else {
        // No tool calls - AI might have stopped or provided text response
        const lastMessage = messages[messages.length - 1];

        if (message.content && message.content.trim() !== "") {
          console.log(`\nüí¨ AI: ${message.content}`);
        }

        if (lastMessage && lastMessage.role === "tool" && !isComplete) {
          console.log("‚ö†Ô∏è  AI stopped unexpectedly, prompting to continue...");

          messages.push({
            role: "assistant",
            content: message.content || "",
          });

          messages.push({
            role: "user",
            content:
              "Continue with the next step. Call the appropriate function now - do not provide explanations.",
          });
        } else {
          console.log("\n‚ö†Ô∏è  AI finished without completing writeExcelFile");
          break;
        }
      }
    }

    if (stepCount >= maxSteps) {
      console.log(
        "\n‚ö†Ô∏è  Reached maximum step limit - stopping to prevent infinite loop"
      );
    }

    // Verify output
    console.log("\nüìä Verifying output...");
    // Preserve the file extension from input
    const fileExt = fileName.substring(fileName.lastIndexOf('.'));
    const fileNameWithoutExt = fileName.substring(0, fileName.lastIndexOf('.'));
    const outputFileName = `processed_${fileNameWithoutExt}${fileExt}`;

    try {
      const verifyResult = await availableFunctions.readExcelFileSample({
        directory: OUTPUT_DIR,
        fileName: outputFileName,
        sampleSize: 3,
      });

      console.log("\nüìä Process Summary:");
      console.log(`   Input file: ${fileName}`);
      console.log(`   Output file: ${outputFileName}`);
      console.log(`   Rows processed: ${verifyResult.totalRows}`);
      console.log(`   Output columns: ${verifyResult.headers.length}`);
      console.log(`   Expected: 10 columns (${STANDARD_COLUMNS.join(", ")})`);
      console.log(
        `   Match: ${
          verifyResult.headers.length === 10
            ? "‚úÖ Perfect"
            : "‚ùå Column count mismatch"
        }`
      );

      if (verifyResult.headers.length === 10) {
        console.log("\nüìã Output columns:");
        verifyResult.headers.forEach((col, idx) => {
          const expected = STANDARD_COLUMNS[idx];
          const match = col === expected ? "‚úÖ" : "‚ùå";
          console.log(
            `   ${match} ${idx + 1}. ${col} ${
              col !== expected ? `(expected: ${expected})` : ""
            }`
          );
        });
      }

      console.log("\n‚ú® AI processing completed successfully!");
      console.log(`üìÅ Output: ${OUTPUT_DIR}/${outputFileName}`);
    } catch (error) {
      console.log("\n‚ö†Ô∏è  Could not verify output file");
      console.log(`   ${error.message}`);
    }
  } catch (error) {
    console.error("\n‚ùå Error:", error.message);
    if (error.response?.data) {
      console.error(
        "Ollama Response:",
        JSON.stringify(error.response.data, null, 2)
      );
    }
    if (error.code === "ECONNREFUSED") {
      console.error("\nüí° Make sure Ollama is running: ollama serve");
      console.error(
        "üí° And the model is installed: ollama pull qwen3-coder:480b-cloud"
      );
    }
  }
}

// Get filename from command line
const fileName = process.argv[2];

if (!fileName) {
  console.error("‚ùå Usage: node process-excel-ai.js <filename.xlsx|filename.csv>");
  console.error("\nSupported formats: .xlsx, .csv");
  console.error("\nExamples:");
  console.error('   node process-excel-ai.js "new test file.xlsx"');
  console.error("   node process-excel-ai.js customers.xlsx");
  console.error("   node process-excel-ai.js data.csv");
  process.exit(1);
}

processExcelWithAI(fileName);
